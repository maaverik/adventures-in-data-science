{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport pandas as pd\nimport geopandas as gpd\nimport requests\nimport shapely\nimport matplotlib.pyplot as plot\n%matplotlib inline\n\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Reading Inputs\n\nHere, we consider Bangalore travel time data for January 2020 to March 2020."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"travel_times = pd.read_csv('/kaggle/input/uber-movement-data/Travel_Times.csv')\ntravel_times_daily = pd.read_csv('/kaggle/input/uber-movement-data/Travel_Times_Daily.csv')\ntravel_times_day = pd.read_csv('/kaggle/input/uber-movement-data/Travel_Times_time_of_day.csv')\ntravel_times_week = pd.read_csv('/kaggle/input/uber-movement-data/Travel_Times_day_of_week.csv')\nbnglr_wards_hourly = pd.read_csv('/kaggle/input/uber-movement-data/bangalore-wards-2020-1-All-HourlyAggregate.csv')\nbnglr_wards_weekly = pd.read_csv('/kaggle/input/uber-movement-data/bangalore-wards-2020-1-WeeklyAggregate.csv')\nbnglr_wards_monthly = pd.read_csv('/kaggle/input/uber-movement-data/bangalore-wards-2020-1-All-MonthlyAggregate.csv')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We'll consider the hourly travel time average to model."},{"metadata":{"trusted":true},"cell_type":"code","source":"bnglr_wards_hourly.head(2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"mean_travel_time_by_hour_of_day = bnglr_wards_hourly.groupby('hod')['mean_travel_time'].mean()/60\nplt = mean_travel_time_by_hour_of_day.plot(kind=\"bar\", figsize=(16,7))\nplt.set_title('Mean travel times around Bangalore',fontsize=20)\nplt.set_xlabel('Hour of day', fontsize=16)\n_ = plt.set_ylabel('Mean travel time in mins', fontsize=16)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# The ward data"},{"metadata":{"trusted":true},"cell_type":"code","source":"bglr=gpd.read_file('/kaggle/input/uber-movement-data/bangalore_wards.json')\nbglr.plot()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(bglr.geometry)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Picking centroids to represent an area"},{"metadata":{"trusted":true},"cell_type":"code","source":"bglr_c = bglr.copy()\nbglr_c.geometry= bglr_c['geometry'].centroid\nfig, ax = plot.subplots(figsize=(9,9))\nbglr.plot(color='grey',ax=ax)\nbglr_c.plot(color='red',ax=ax)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"id_to_dest = travel_times[['Destination Movement ID', 'Destination Display Name']]\nid_to_dest.columns = ['id', 'name']\nid_to_dest.head()\n","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Cleaning up data for analysis\n\nGot source and destination data and removed unneeded columns like geometric_mean_travel_time and geometric_standard_deviation_travel_time."},{"metadata":{"trusted":true},"cell_type":"code","source":"time_df = pd.merge(bnglr_wards_hourly, id_to_dest, left_on=['sourceid'], right_on=['id'], how='inner')\ntime_df = time_df.drop(columns=['id', 'geometric_mean_travel_time', 'geometric_standard_deviation_travel_time'])\ntime_df = time_df.rename(columns={'name': 'Source Name'})\ntime_df = pd.merge(time_df, id_to_dest, left_on=['dstid'], right_on=['id'], how='inner')\ntime_df = time_df.loc[time_df['sourceid'] != time_df['dstid']]\ntime_df = time_df.drop(columns=['id'])\ntime_df = time_df.rename(columns={'name': 'Destination Name'})\ntime_df = time_df.sort_values(by=['sourceid', 'dstid', 'hod'])\ntime_df.tail(5)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bglr_c.geometry","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bglr_c.DISPLAY_NAME","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"time_df2 = pd.merge(time_df, bglr_c, left_on=['Source Name'], right_on=['DISPLAY_NAME'], how='inner')\ntime_df2 = time_df2.drop(columns=['WARD_NO', 'MOVEMENT_ID', 'DISPLAY_NAME'])\ntime_df2 = time_df2.rename(columns = {'WARD_NAME': 'Source Ward Name', 'geometry': 'Source Geometry'})\ntime_df2 = pd.merge(time_df2, bglr_c, left_on=['Destination Name'], right_on=['DISPLAY_NAME'], how='inner')\ntime_df2 = time_df2.drop(columns=['WARD_NO', 'MOVEMENT_ID', 'DISPLAY_NAME'])\ntime_df2 = time_df2.rename(columns = {'WARD_NAME': 'Destination Ward Name', 'geometry': 'Destination Geometry'})\ntime_df2.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\ndef save_object(obj, filename):\n    with open(filename, 'wb') as output:  # Overwrites any existing file.\n        pickle.dump(obj, output, pickle.HIGHEST_PROTOCOL)\n\nimport os.path\ndef file_exists(filename):\n    return os.path.exists(filename)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Calculating distances to use as a feature"},{"metadata":{"trusted":true},"cell_type":"code","source":"import geopy.distance\n\ndef calc_distance(x):\n    src_point = (x['Source Geometry'].y, x['Source Geometry'].x)\n    dest_point = (x['Destination Geometry'].y, x['Destination Geometry'].x)\n    return geopy.distance.geodesic(src_point, dest_point).kilometers\n\nfilename = '/kaggle/input/calc-data/Df_with_geodesic_distance.bin'\nif file_exists(filename):\n    with open(filename, 'rb') as file:\n        df = pickle.load(file)\nelse:\n    time_df2['Geodesic Distance'] = time_df2.apply(func = calc_distance, axis=1)\n    save_object(time_df2, filename)\n    df = time_df2\ndf.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import osrm\n\n# def calc_osrm_distance(x):\n#     src_point = (x['Source Geometry'].y, x['Source Geometry'].x)\n#     dest_point = (x['Destination Geometry'].y, x['Destination Geometry'].x)\n#     result = osrm.simple_route(src_point, dest_point, output='route', overview=\"full\", geometry='wkt')\n#     return result[0]['distance']\n\n\n# filename = 'Df_with_osrm_distance.bin'\n# if file_exists(filename):\n#     df = pickle.load(filename)\n# else:\n#     df['OSRM Distance'] = df.apply(func = calc_osrm_distance, axis=1)\n#     save_object(df, filename)\n# df.sample(3)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# !pip install osrm-py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# import osrm\n\n# client = osrm.Client()\n\n# response = client.route(\n#     coordinates=[[13.102805, 77.560038], [13.121709, 77.580422]],\n#     overview=osrm.overview.full)\n\n# print(response)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def compare(actual, predicted):\n    actual = [act[0] for act in actual[outcome].values.tolist()]\n    predicted = predicted.tolist()\n    return pd.DataFrame(data = {'actual': actual, 'prediction': predicted})","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"final_df = df.copy()\nfinal_df['Source lat'] = final_df['Source Geometry'].apply(lambda pt: float(pt.y))\nfinal_df['Source long'] = final_df['Source Geometry'].apply(lambda pt: float(pt.x))\nfinal_df['Dest lat'] = final_df['Destination Geometry'].apply(lambda pt: float(pt.y))\nfinal_df['Dest long'] = final_df['Destination Geometry'].apply(lambda pt: float(pt.x))\n\ntest_sample = final_df.sample(20)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# test_sample","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Modelling"},{"metadata":{},"cell_type":"markdown","source":"Model 1"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['Source lat', 'Source long', 'Dest lat', 'Dest long', 'hod', 'Geodesic Distance']\noutcome = ['mean_travel_time']\nfinal_df = final_df[features + outcome]\n\nimport xgboost as xgb\n\nfilename = '/kaggle/input/calc-data/XGB_model_1.bin'\nif file_exists(filename):\n    with open(filename, 'rb') as file:\n        my_model = pickle.load(file)\nelse:\n    my_model = xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\n    my_model.fit(final_df[features], final_df[outcome],\n             verbose=False)\n    save_object(my_model, filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sample1 = test_sample.copy()\ntest_sample1 = test_sample1[features]\nactuals = test_sample[outcome]\nprediction = my_model.predict(test_sample1)\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(actuals, prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare(actuals, prediction)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Model 2"},{"metadata":{"trusted":true},"cell_type":"code","source":"features = ['hod', 'Geodesic Distance']\noutcome = ['mean_travel_time']\nfinal_df = final_df[features + outcome]\n\nfilename = 'XGB_model_2.bin'\nif file_exists(filename):\n    with open(filename, 'rb') as file:\n        my_model2 = pickle.load(file)\nelse:\n    my_model2 = xgb.XGBRegressor(n_estimators=500, learning_rate=0.05, n_jobs=4)\n    my_model2.fit(final_df[features], final_df[outcome],\n             verbose=False)\n    save_object(my_model2, filename)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_sample2 = test_sample.copy()\ntest_sample2 = test_sample2[features]\nactuals = test_sample[outcome]\nprediction = my_model2.predict(test_sample2)\n\nfrom sklearn.metrics import mean_squared_error\nmean_squared_error(actuals, prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"compare(actuals, prediction)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def get_distance(lat1, long1, lat2, long2):\n    src_point = (lat1, long1)\n    dest_point = (lat2, long2)\n    return geopy.distance.geodesic(src_point, dest_point).kilometers\n\ndef prepare_df(lat1, long1, lat2, long2, hod):\n    distance = get_distance(lat1, long1, lat2, long2)\n    return pd.DataFrame(columns = ['Source lat', 'Source long', 'Dest lat', 'Dest long', 'hod', 'Geodesic Distance'],\n                 data = [[lat1, long1, lat2, long2, hod, distance]])\n    \ndef predict(df):\n    return my_model.predict(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lat1 = 13.002385\nlong1 = 77.568491\nlat2 = 13.061071\nlong2 = 77.597371\nhod = 10\n\ndf = prepare_df(lat1, long1, lat2, long2, hod)\npredict(df)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}